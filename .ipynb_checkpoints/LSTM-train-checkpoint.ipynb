{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "861a6356-6cfd-4fe2-a69e-fb2ca4094350",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e768327e-7977-4603-850b-aeb3779d333d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53d13b0-dc7e-4bca-8688-e0d426788d72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78209c89-cbee-451b-b5bc-99ed44177808",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9ccdc18c-f4cc-4e9d-9105-7d0e992f1e80",
   "metadata": {},
   "source": [
    "## LSTM-train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fabd5886-9b49-44d6-a16b-911575af8faf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7d7e1c-736c-45b6-a281-7b91c7e134f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650c76b5-b1ab-4d77-b7f6-67ca3d560a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================== Imports ===================\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, RepeatVector, TimeDistributed\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#=================== Evaluation Metrics ===================\n",
    "def ade(gt, pred):\n",
    "    # Average Displacement Error (mean over all time steps)\n",
    "    dists = np.linalg.norm(pred - gt, axis=-1)\n",
    "    return dists.mean()\n",
    "\n",
    "def mae(gt, pred):\n",
    "    # Mean Absolute Error\n",
    "    return float(np.mean(np.abs(pred - gt)))\n",
    "\n",
    "def rmse(gt, pred):\n",
    "    # Root Mean Squared Error\n",
    "    return float(np.sqrt(np.mean((pred - gt) ** 2)))\n",
    "\n",
    "def fde(gt, pred):\n",
    "    # Final Displacement Error (distance at last point)\n",
    "    return np.linalg.norm(gt[:, -1] - pred[:, -1], axis=-1).mean()\n",
    "\n",
    "#=================== Extract Sequences from Annotations ===================\n",
    "def extract_center_sequences(annotation_file, past_len, future_len, x_range=(-51, 51), y_range=(-5, 20)):\n",
    "    with open(annotation_file, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "    cuboid_trajs = {}\n",
    "    for frame_idx, frame_dict in enumerate(data):\n",
    "        if \"cuboids\" not in frame_dict:\n",
    "            continue\n",
    "        for cuboid in frame_dict[\"cuboids\"]:\n",
    "            cid = cuboid[\"uuid\"]\n",
    "            px, py = cuboid[\"position\"][\"x\"], cuboid[\"position\"][\"y\"]\n",
    "            if not (x_range[0] <= px <= x_range[1] and y_range[0] <= py <= y_range[1]):\n",
    "                continue\n",
    "            cuboid_trajs.setdefault(cid, []).append((frame_idx, px, py))\n",
    "\n",
    "    X_all, Y_all = [], []\n",
    "    for traj in cuboid_trajs.values():\n",
    "        traj.sort(key=lambda t: t[0])\n",
    "        positions = np.array([[t[1], t[2]] for t in traj], dtype=np.float32)\n",
    "        n = len(positions)\n",
    "        if n < past_len + future_len:\n",
    "            continue\n",
    "        for start_idx in range(n - past_len - future_len + 1):\n",
    "            past = positions[start_idx : start_idx + past_len]\n",
    "            future = positions[start_idx + past_len : start_idx + past_len + future_len]\n",
    "            vels = np.diff(past, axis=0, prepend=past[0:1])\n",
    "            enriched = np.concatenate([past, vels], axis=1)  # shape: (past_len, 4)\n",
    "            X_all.append(enriched)\n",
    "            Y_all.append(future - past[-1])  # relative future positions\n",
    "    return np.array(X_all, dtype=np.float32), np.array(Y_all, dtype=np.float32)\n",
    "\n",
    "#=================== Define LSTM Model ===================\n",
    "def build_model(past_len, future_len):\n",
    "    model = Sequential([\n",
    "        LSTM(128, input_shape=(past_len, 4), return_sequences=True),\n",
    "        Dropout(0.3),\n",
    "        LSTM(128, return_sequences=True),\n",
    "        Dropout(0.3),\n",
    "        LSTM(128, return_sequences=True),\n",
    "        Dropout(0.3),\n",
    "        LSTM(128, return_sequences=True),\n",
    "        Dropout(0.3),\n",
    "        LSTM(128, return_sequences=False),  # last encoder step\n",
    "        Dropout(0.3),\n",
    "\n",
    "        RepeatVector(future_len),           # prepare for decoder\n",
    "        LSTM(128, return_sequences=True),\n",
    "        Dropout(0.3),\n",
    "        LSTM(128, return_sequences=True),\n",
    "        Dropout(0.3),\n",
    "        LSTM(128, return_sequences=True),\n",
    "        Dropout(0.3),\n",
    "        LSTM(128, return_sequences=True),\n",
    "        Dropout(0.3),\n",
    "        LSTM(128, return_sequences=True),\n",
    "        Dropout(0.3),\n",
    "        TimeDistributed(Dense(64, activation='relu')),\n",
    "        TimeDistributed(Dense(2))  # output 2D point\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='mae')\n",
    "    return model\n",
    "\n",
    "#=================== Stepwise Online Prediction ===================\n",
    "def online_stepwise_prediction(model, full_sequence, normX, denormY, past_len=5, steps=10):\n",
    "    full_sequence = np.array(full_sequence)\n",
    "    past = full_sequence[:past_len].tolist()\n",
    "    gt_future = full_sequence[past_len:past_len + steps]\n",
    "    predicted_points = []\n",
    "\n",
    "    for i in range(steps):\n",
    "        past_arr = np.array(past[-past_len:])\n",
    "        vels = np.diff(past_arr, axis=0, prepend=past_arr[0:1])\n",
    "        enriched = np.concatenate([past_arr, vels], axis=1).reshape(1, past_len, 4)\n",
    "        x_in = normX(enriched)\n",
    "        pred_norm = model.predict(x_in, verbose=0)[0]\n",
    "        rel_disp = denormY(pred_norm)[0]\n",
    "        pred = past[-1] + rel_disp\n",
    "        predicted_points.append(pred)\n",
    "\n",
    "        # Use GT if available, else use prediction (auto-regressive)\n",
    "        past.append(gt_future[i] if i < len(gt_future) else pred)\n",
    "\n",
    "    return np.array(predicted_points), np.array(gt_future)\n",
    "\n",
    "#=================== Training Wrapper for Region ===================\n",
    "def train_for_y_range(train_file, test_file, y_range, model_suffix):\n",
    "    past_len = 5\n",
    "    future_len = 3\n",
    "\n",
    "    # Load and preprocess sequences\n",
    "    X_train, Y_train = extract_center_sequences(train_file, past_len, future_len, y_range=y_range)\n",
    "    X_test, Y_test = extract_center_sequences(test_file, past_len, future_len, y_range=y_range)\n",
    "    print(f\"Train samples: {len(X_train)} | Test samples: {len(X_test)} | y_range: {y_range}\")\n",
    "    if len(X_train) == 0 or len(X_test) == 0:\n",
    "        print(\"No data found.\")\n",
    "        return\n",
    "\n",
    "    # Normalize data\n",
    "    X_flat = X_train.reshape(-1, 4)\n",
    "    Y_flat = Y_train.reshape(-1, 2)\n",
    "    X_mean, X_std = X_flat.mean(0), X_flat.std(0) + 1e-8\n",
    "    Y_mean, Y_std = Y_flat.mean(0), Y_flat.std(0) + 1e-8\n",
    "    normX = lambda x: (x - X_mean) / X_std\n",
    "    normY = lambda y: (y - Y_mean) / Y_std\n",
    "    denormY = lambda y: y * Y_std + Y_mean\n",
    "\n",
    "    # Normalize input/output\n",
    "    X_train_n, Y_train_n = normX(X_train), normY(Y_train)\n",
    "    X_test_n, Y_test_n = normX(X_test), normY(Y_test)\n",
    "\n",
    "    # Train model\n",
    "    model = build_model(past_len, future_len)\n",
    "    history = model.fit(\n",
    "        X_train_n, Y_train_n,\n",
    "        validation_data=(X_test_n, Y_test_n),\n",
    "        epochs=100, batch_size=256\n",
    "    )\n",
    "\n",
    "    # Plot training curve\n",
    "    plt.figure()\n",
    "    plt.plot(history.history['loss'], label='Train')\n",
    "    plt.plot(history.history['val_loss'], label='Val')\n",
    "    plt.title(f\"Training Loss for {model_suffix}\")\n",
    "    plt.xlabel(\"Epoch\"); plt.ylabel(\"MAE\")\n",
    "    plt.grid(); plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # Evaluate\n",
    "    Y_pred_n = model.predict(X_test_n)\n",
    "    Y_pred = denormY(Y_pred_n)\n",
    "    Y_pred_abs = Y_pred + X_test[:, -1, :2][:, np.newaxis, :]\n",
    "    Y_gt_abs = Y_test + X_test[:, -1, :2][:, np.newaxis, :]\n",
    "\n",
    "    print(f\"→ Test ADE:   {ade(Y_gt_abs, Y_pred_abs):.4f}\")\n",
    "    print(f\"→ Test MAE:   {mae(Y_gt_abs, Y_pred_abs):.4f}\")\n",
    "    print(f\"→ Test RMSE:  {rmse(Y_gt_abs, Y_pred_abs):.4f}\")\n",
    "    print(f\"→ Test FDE:   {fde(Y_gt_abs, Y_pred_abs):.4f}\")\n",
    "\n",
    "    # One-sample step-by-step prediction for inspection\n",
    "    past_abs = X_test[0, :, 0:2]\n",
    "    future_abs = Y_test[0] + past_abs[-1]\n",
    "    full_seq = np.concatenate((past_abs, future_abs), axis=0)\n",
    "    pred_pts, gt_future = online_stepwise_prediction(model, full_seq, normX, denormY, past_len=past_len, steps=future_len)\n",
    "\n",
    "    print(f\"→ Online one-sample:\")\n",
    "    print(f\"  ADE  = {ade(gt_future, pred_pts):.4f}\")\n",
    "    print(f\"  MAE  = {mae(gt_future, pred_pts):.4f}\")\n",
    "    print(f\"  RMSE = {rmse(gt_future, pred_pts):.4f}\")\n",
    "    print(f\"  FDE  = {fde(gt_future, pred_pts):.4f}\")\n",
    "\n",
    "    # Plot sample prediction\n",
    "    plt.figure()\n",
    "    plt.plot(full_seq[:past_len, 0], full_seq[:past_len, 1], 'go-', label='Past')\n",
    "    plt.plot(gt_future[:, 0], gt_future[:, 1], 'b^-', label='GT Future')\n",
    "    plt.plot(pred_pts[:, 0], pred_pts[:, 1], 'rs--', label='Predicted')\n",
    "    plt.title(f\"LSTM Prediction for {model_suffix}\")\n",
    "    plt.axis('equal'); plt.grid(); plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # Save model and normalization\n",
    "    model.save(f\"center_lstm_model_22{model_suffix}.h5\")\n",
    "    np.save(f\"center_lstm_norm_22{model_suffix}.npy\", {\n",
    "        \"X_mean\": X_mean.tolist(),\n",
    "        \"X_std\": X_std.tolist(),\n",
    "        \"Y_mean\": Y_mean.tolist(),\n",
    "        \"Y_std\": Y_std.tolist(),\n",
    "    })\n",
    "    print(f\"Model and normalization saved for {model_suffix}.\")\n",
    "\n",
    "#=================== Main Runner ===================\n",
    "def main():\n",
    "    train_file = \"3d_ann.json\"\n",
    "    test_file  = \"KF52_ann.json\"\n",
    "    # Train model for right-side cuboids\n",
    "    train_for_y_range(train_file, test_file, y_range=(-5, 7.5), model_suffix=\"region_right\")\n",
    "    # Train model for left-side cuboids\n",
    "    train_for_y_range(train_file, test_file, y_range=(7.5, 20), model_suffix=\"region_left\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
